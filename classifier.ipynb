{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4527184e",
   "metadata": {},
   "source": [
    "# Chest X-Ray Disease Classification (Multi-Label)\n",
    "\n",
    "Train an EfficientNet-B3 model for multi-label classification of 15 chest disease categories from the NIH Chest X-Ray dataset.\n",
    "\n",
    "## Dataset\n",
    "- 31,416 chest X-ray images\n",
    "- Split: 21,991 train / 4,712 validation / 4,713 test\n",
    "- 15 disease classes (multi-label: each image can have 0-15 diseases)\n",
    "\n",
    "## Model\n",
    "- Architecture: EfficientNet-B3 pretrained on ImageNet\n",
    "- Classification Type: **Multi-Label** (BCEWithLogitsLoss)\n",
    "- Image Size: 300x300 (optimized for EfficientNet-B3)\n",
    "- Batch Size: 192 (with mixed precision)\n",
    "- Optimizer: AdamW with weight decay 0.01\n",
    "- Scheduler: CosineAnnealingWarmRestarts\n",
    "- Data augmentation: Mixup, horizontal flip, rotation, affine, color jitter, erasing\n",
    "- Mixed Precision: Enabled (AMP)\n",
    "\n",
    "## Results\n",
    "- Previous single-label baseline: 37% (ResNet50)\n",
    "- Target multi-label accuracy: 75-80%\n",
    "- Training in progress..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df7661e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evanp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# IMPORTS\n",
    "# Load required libraries for PyTorch training and evaluation\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import os \n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, models\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import timm  # For EfficientNet models\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed precision training\n",
    "import random  # For Mixup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39158fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# DATASET CLASS - MULTI-LABEL\n",
    "# Custom PyTorch dataset for loading chest X-ray images with multi-label support\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "class ChestXrayDatasetMultiLabel(Dataset):\n",
    "    \"\"\"Dataset for NIH Chest X-ray with 15 disease classes (multi-label)\"\"\"\n",
    "    \n",
    "    def __init__(self, metadata_csv, image_dir, disease_classes, transform=None):\n",
    "        self.metadata = pd.read_csv(metadata_csv)\n",
    "        self.image_dir = image_dir\n",
    "        self.disease_classes = disease_classes\n",
    "        self.transform = transform\n",
    "        self.num_classes = len(disease_classes)\n",
    "        \n",
    "        print(f\"Loaded {len(self.metadata)} samples from {metadata_csv}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.metadata)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata.iloc[idx]\n",
    "        \n",
    "        # Get image path - check both naming conventions\n",
    "        img_name = row['Image Index']\n",
    "        \n",
    "        # Try to find image in any of the class folders\n",
    "        img_path = None\n",
    "        for class_folder in self.disease_classes:\n",
    "            potential_path = os.path.join(self.image_dir, class_folder, img_name)\n",
    "            if os.path.exists(potential_path):\n",
    "                img_path = potential_path\n",
    "                break\n",
    "        \n",
    "        # If not found in class folders, try root\n",
    "        if img_path is None:\n",
    "            img_path = os.path.join(self.image_dir, img_name)\n",
    "        \n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Create multi-label vector (binary for each disease)\n",
    "        finding_labels = row['Finding Labels']\n",
    "        label_vector = torch.zeros(self.num_classes, dtype=torch.float32)\n",
    "        \n",
    "        # Parse the disease labels (could be single or multiple separated by |)\n",
    "        if pd.notna(finding_labels):\n",
    "            diseases = [d.strip() for d in str(finding_labels).split('|')]\n",
    "            for disease in diseases:\n",
    "                if disease in self.disease_classes:\n",
    "                    idx_disease = self.disease_classes.index(disease)\n",
    "                    label_vector[idx_disease] = 1.0\n",
    "        \n",
    "        return image, label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7030cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 15\n",
      "Classes: ['Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion', 'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'No_Finding', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax']\n",
      "\n",
      "Using MULTI-LABEL classification (each image can have 0-15 diseases)\n",
      "Loaded 28000 samples from data/train_metadata.csv\n",
      "Loaded 6000 samples from data/val_metadata.csv\n",
      "Loaded 6000 samples from data/test_metadata.csv\n",
      "\n",
      "Dataset sizes:\n",
      "Train: 28,000 images\n",
      "Val:   6,000 images\n",
      "Test:  6,000 images\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# LOAD DATA & TRANSFORMS - MULTI-LABEL\n",
    "# Load class mapping and create train/val/test datasets with transforms\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Define disease classes (15 classes)\n",
    "DISEASE_CLASSES = [\n",
    "    'Atelectasis', 'Cardiomegaly', 'Consolidation', 'Edema', 'Effusion',\n",
    "    'Emphysema', 'Fibrosis', 'Hernia', 'Infiltration', 'Mass',\n",
    "    'Nodule', 'No_Finding', 'Pleural_Thickening', 'Pneumonia', 'Pneumothorax'\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(DISEASE_CLASSES)\n",
    "print(f\"Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"Classes: {DISEASE_CLASSES}\")\n",
    "print(f\"\\nUsing MULTI-LABEL classification (each image can have 0-15 diseases)\")\n",
    "\n",
    "# Data transforms with augmentation for training\n",
    "# EfficientNet-B3 performs better with 300x300 images\n",
    "# Enhanced augmentation for more robust training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),  # Flip X-rays horizontally\n",
    "    transforms.RandomRotation(degrees=10),    # Slight rotation\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),  # Random shifts\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # Adjust brightness/contrast\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.2))  # Randomly erase patches\n",
    "])\n",
    "\n",
    "# Standard transforms for validation/test (no augmentation)\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Data directory (modify this path to match your local setup)\n",
    "DATA_DIR = 'C:/xray_data'  # Change to your data location\n",
    "\n",
    "# Create multi-label datasets\n",
    "train_dataset = ChestXrayDatasetMultiLabel(\n",
    "    metadata_csv=os.path.join(DATA_DIR, 'train_metadata.csv'),\n",
    "    image_dir=os.path.join(DATA_DIR, 'train'),\n",
    "    disease_classes=DISEASE_CLASSES,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset = ChestXrayDatasetMultiLabel(\n",
    "    metadata_csv=os.path.join(DATA_DIR, 'val_metadata.csv'),\n",
    "    image_dir=os.path.join(DATA_DIR, 'val'),\n",
    "    disease_classes=DISEASE_CLASSES,\n",
    "    transform=eval_transform\n",
    ")\n",
    "\n",
    "test_dataset = ChestXrayDatasetMultiLabel(\n",
    "    metadata_csv=os.path.join(DATA_DIR, 'test_metadata.csv'),\n",
    "    image_dir=os.path.join(DATA_DIR, 'test'),\n",
    "    disease_classes=DISEASE_CLASSES,\n",
    "    transform=eval_transform\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset sizes:\")\n",
    "print(f\"Train: {len(train_dataset):,} images\")\n",
    "print(f\"Val:   {len(val_dataset):,} images\")\n",
    "print(f\"Test:  {len(test_dataset):,} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5444db07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4080\n",
      "GPU Memory: 17.17 GB\n",
      "\n",
      "Model: EfficientNet-B3 (Multi-Label)\n",
      "Total parameters: 10,719,287\n",
      "Batch size: 192 (increased with mixed precision)\n",
      "Input image size: 300x300\n",
      "Optimizer: AdamW with weight decay 0.01\n",
      "Scheduler: CosineAnnealingWarmRestarts\n",
      "Loss: BCEWithLogitsLoss (multi-label)\n",
      "Augmentation: Mixup (alpha=0.2)\n",
      "Mixed Precision: Enabled (AMP)\n",
      "\n",
      "Multi-label: Each image can have 0-15 diseases simultaneously\n",
      "\n",
      "Model: EfficientNet-B3 (Multi-Label)\n",
      "Total parameters: 10,719,287\n",
      "Batch size: 192 (increased with mixed precision)\n",
      "Input image size: 300x300\n",
      "Optimizer: AdamW with weight decay 0.01\n",
      "Scheduler: CosineAnnealingWarmRestarts\n",
      "Loss: BCEWithLogitsLoss (multi-label)\n",
      "Augmentation: Mixup (alpha=0.2)\n",
      "Mixed Precision: Enabled (AMP)\n",
      "\n",
      "Multi-label: Each image can have 0-15 diseases simultaneously\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evanp\\AppData\\Local\\Temp\\ipykernel_5728\\3733537523.py:60: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# MIXUP AUGMENTATION - MULTI-LABEL\n",
    "# Blends two images and their labels for better generalization\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    \"\"\"Apply Mixup augmentation for multi-label\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    \"\"\"Compute loss for mixed samples (multi-label compatible)\"\"\"\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# MODEL SETUP\n",
    "# Create DataLoaders and initialize EfficientNet-B3 with GPU acceleration\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Larger batch size with mixed precision\n",
    "train_loader = DataLoader(train_dataset, batch_size=192, shuffle=True, num_workers=0, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=192, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=192, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nUsing device: {device}\")\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    torch.backends.cudnn.benchmark = True  # Speed optimization\n",
    "\n",
    "# Model: EfficientNet-B3\n",
    "# EfficientNet models are more efficient and typically achieve better accuracy\n",
    "model = timm.create_model('efficientnet_b3', pretrained=True, num_classes=NUM_CLASSES)\n",
    "model = model.to(device)\n",
    "\n",
    "# BCEWithLogitsLoss for multi-label classification\n",
    "# Combines sigmoid + BCE loss for numerical stability\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# AdamW provides better regularization than Adam\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "\n",
    "# Cosine Annealing with Warm Restarts for better LR scheduling\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "# Mixed precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "print(f\"\\nModel: EfficientNet-B3 (Multi-Label)\")\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Batch size: 192 (increased with mixed precision)\")\n",
    "print(f\"Input image size: 300x300\")\n",
    "print(f\"Optimizer: AdamW with weight decay 0.01\")\n",
    "print(f\"Scheduler: CosineAnnealingWarmRestarts\")\n",
    "print(f\"Loss: BCEWithLogitsLoss (multi-label)\")\n",
    "print(f\"Augmentation: Mixup (alpha=0.2)\")\n",
    "print(f\"Mixed Precision: Enabled (AMP)\")\n",
    "print(f\"\\nMulti-label: Each image can have 0-15 diseases simultaneously\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a643973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting multi-label training...\n",
      "Estimated total time: ~8.3 hours (with AMP speedup)\n",
      "\n",
      "Epoch 1/50\n",
      "Learning Rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evanp\\AppData\\Local\\Temp\\ipykernel_5728\\2493280206.py:35: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# TRAINING LOOP - MULTI-LABEL\n",
    "# Train EfficientNet-B3 with Mixed Precision, Mixup, and Cosine Annealing\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "num_epochs = 50\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(\"\\nStarting multi-label training...\")\n",
    "print(f\"Estimated total time: ~{num_epochs * 10 / 60:.1f} hours (with AMP speedup)\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Training with Mixed Precision and Mixup\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Apply Mixup augmentation\n",
    "        images, labels_a, labels_b, lam = mixup_data(images, labels, alpha=0.2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision forward pass\n",
    "        with autocast():\n",
    "            outputs = model(images)\n",
    "            loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "        \n",
    "        # Mixed precision backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        # Multi-label accuracy: Apply sigmoid and threshold at 0.5\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        mixed_labels = lam * labels_a + (1 - lam) * labels_b\n",
    "        correct += (preds == (mixed_labels > 0.5).float()).sum().item()\n",
    "        total += labels.numel()  # Total number of label predictions\n",
    "        \n",
    "        if (batch_idx + 1) % 25 == 0:  # Print progress every 25 batches\n",
    "            print(f\"  Batch [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100 * correct / total\n",
    "    \n",
    "    # Validation - Multi-label\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Apply sigmoid and threshold for multi-label\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            \n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.numel()\n",
    "            \n",
    "            # Store for AUC calculation\n",
    "            all_preds.append(torch.sigmoid(outputs).cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    \n",
    "    val_acc = 100 * val_correct / val_total\n",
    "    \n",
    "    # Calculate mean AUC-ROC (optional but important for multi-label)\n",
    "    all_preds = np.vstack(all_preds)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    try:\n",
    "        val_auc = roc_auc_score(all_labels, all_preds, average='macro')\n",
    "    except:\n",
    "        val_auc = 0.0\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Val Acc: {val_acc:.2f}%, Val AUC: {val_auc:.4f}\")\n",
    "    print(f\"Epoch Time: {epoch_time/60:.1f} minutes\")\n",
    "    \n",
    "    # Cosine Annealing scheduling (steps every epoch)\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_efficientnet_b3.pth')\n",
    "        print(f\"✓ Saved best model (val_acc: {val_acc:.2f}%)\")\n",
    "    \n",
    "    # Estimate remaining time\n",
    "    remaining_epochs = num_epochs - (epoch + 1)\n",
    "    est_time_remaining = remaining_epochs * epoch_time / 3600\n",
    "    print(f\"Estimated time remaining: {est_time_remaining:.1f} hours\")\n",
    "\n",
    "print(f\"\\nTraining complete! Best validation accuracy: {best_val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4618e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# TEST EVALUATION\n",
    "# Load best model and evaluate on test set with per-class accuracy\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_efficientnet_b3.pth'))\n",
    "model.eval()\n",
    "\n",
    "test_labels = []\n",
    "test_preds = []\n",
    "\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        test_labels.extend(labels.cpu().numpy())\n",
    "        test_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "test_accuracy = accuracy_score(test_labels, test_preds)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "# Per-class accuracy\n",
    "print(\"\\nPer-Class Accuracy:\")\n",
    "for i in range(NUM_CLASSES):\n",
    "    class_mask = np.array(test_labels) == i\n",
    "    if class_mask.sum() > 0:\n",
    "        class_acc = accuracy_score(\n",
    "            np.array(test_labels)[class_mask],\n",
    "            np.array(test_preds)[class_mask]\n",
    "        )\n",
    "        print(f\"  {class_mapping[i]:25} - {class_acc*100:.2f}%\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87fca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# VISUALIZE RESULTS\n",
    "# Generate and save confusion matrix heatmap for model performance analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=[class_mapping[i] for i in range(NUM_CLASSES)],\n",
    "            yticklabels=[class_mapping[i] for i in range(NUM_CLASSES)])\n",
    "plt.title('Confusion Matrix - EfficientNet-B3')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_efficientnet_b3.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\nConfusion matrix saved to 'confusion_matrix_efficientnet_b3.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08190e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------\n",
    "# INFERENCE ON SINGLE IMAGE\n",
    "# Test the trained model on a new chest X-ray image\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def predict_image(image_path, model, device, transform, class_mapping, top_k=3):\n",
    "    \n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
    "        top_probs, top_indices = torch.topk(probabilities, top_k)\n",
    "    \n",
    "    # Format results\n",
    "    predictions = []\n",
    "    for prob, idx in zip(top_probs[0], top_indices[0]):\n",
    "        disease_name = class_mapping[idx.item()]\n",
    "        predictions.append((disease_name, prob.item()))\n",
    "    \n",
    "    return image, predictions\n",
    "\n",
    "\n",
    "# Example usage: Test on a random image from test set\n",
    "import random\n",
    "\n",
    "# Get a random test image\n",
    "test_image_path = random.choice(test_dataset.image_paths)\n",
    "print(f\"Testing on: {test_image_path}\\n\")\n",
    "\n",
    "# Make prediction\n",
    "original_image, predictions = predict_image(\n",
    "    test_image_path, \n",
    "    model, \n",
    "    device, \n",
    "    eval_transform,  # Use eval_transform (no augmentation for inference)\n",
    "    class_mapping, \n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Top 5 Predictions:\")\n",
    "print(\"-\" * 50)\n",
    "for i, (disease, prob) in enumerate(predictions, 1):\n",
    "    print(f\"{i}. {disease:25} - {prob*100:.2f}%\")\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(original_image, cmap='gray')\n",
    "plt.title(f'Input X-ray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "diseases = [pred[0] for pred in predictions]\n",
    "probs = [pred[1] * 100 for pred in predictions]\n",
    "plt.barh(diseases, probs, color='steelblue')\n",
    "plt.xlabel('Confidence (%)')\n",
    "plt.title('Top 5 Predictions')\n",
    "plt.xlim(0, 100)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
